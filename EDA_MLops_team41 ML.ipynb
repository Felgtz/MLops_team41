{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo monta Drive si estamos en Colab\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "else:\n",
    "    print(\"No Colab: saltando montaje de Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "CLEAN_PATH = Path(\"data/processed/clean.csv\")\n",
    "assert CLEAN_PATH.exists(), f\"No existe {CLEAN_PATH}. Corre el stage de cleaning primero.\"\n",
    "dataset_modified = pd.read_csv(CLEAN_PATH).convert_dtypes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDj06kgyWBCW"
   },
   "source": [
    "##Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5020,
     "status": "ok",
     "timestamp": 1760207922019,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "qWgV6_Isnq_m",
    "outputId": "940b4a94-f9ce-486d-a853-5530cb344fca"
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros (el runner/papermill los puede sobreescribir si quieres)\n",
    "PATH_IN = \"data/processed/clean.csv\"                  # entrada oficial del stage clean\n",
    "MODEL_OUT = \"models/best_model.joblib\"                # si dejas un “mejor modelo” único\n",
    "REPORT_OUT = \"reports/models/cv_results_summary.csv\"  # resumen de CV\n",
    "METRICS_OUT = \"reports/models/metrics.json\"           # métricas para DVC\n",
    "\n",
    "# Carga de datos\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"reports/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if Path(PATH_IN).exists():\n",
    "    dataset_modified = pd.read_csv(PATH_IN, low_memory=False).convert_dtypes()\n",
    "elif Path(\"df_final_validated.csv\").exists():  # fallback por si alguien aún lo usa\n",
    "    dataset_modified = pd.read_csv(\"df_final_validated.csv\", low_memory=False).convert_dtypes()\n",
    "else:\n",
    "    raise FileNotFoundError(\"No se encontró data/processed/clean.csv ni df_final_validated.csv\")\n",
    "\n",
    "print(\"dataset_modified:\", dataset_modified.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1760207922028,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "6Xjcnm83QftW"
   },
   "outputs": [],
   "source": [
    "# Patched: evitar fallo fuera de Colab\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print('Google Drive montado (Colab).')\n",
    "except Exception:\n",
    "    print('No Colab: saltando montaje de Drive.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsmx06sfWGNq"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1760207922827,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "62ja-jXqUjOc",
    "outputId": "8028b7ef-9fce-4cba-a997-6cc28ecbb33f"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')\n",
    "#os.chdir('/content/drive/MyDrive/Colab Notebooks/3_Trimestre/MLOps/Semana_4/Tarea')\n",
    "#os.chdir('/content/drive/MyDrive/Colab Notebooks/MNA/4rto_Trimestre/MLOps/Semana_4/Tarea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data (agnóstico a Colab) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# (Opcional) Si estás en Colab, monta Drive; en local no hace nada\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    from google.colab import drive  # type: ignore\n",
    "    print(\"Colab detectado -> montando Drive…\")\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "except Exception:\n",
    "    pass  # no estamos en Colab\n",
    "\n",
    "# Ruta oficial del pipeline (DVC) y fallback local\n",
    "CLEAN_PATH = Path(\"data/processed/clean.csv\")\n",
    "FALLBACK_PATH = Path(\"df_final_validated.csv\")\n",
    "\n",
    "if CLEAN_PATH.exists():\n",
    "    dataset_modified = pd.read_csv(CLEAN_PATH, low_memory=False)\n",
    "    print(f\"✓ Cargado {CLEAN_PATH} ->\", dataset_modified.shape)\n",
    "elif FALLBACK_PATH.exists():\n",
    "    dataset_modified = pd.read_csv(FALLBACK_PATH, low_memory=False)\n",
    "    print(f\"✓ Cargado {FALLBACK_PATH} ->\", dataset_modified.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro data/processed/clean.csv ni df_final_validated.csv.\\n\"\n",
    "        \"Corre el stage de cleaning (python -m dvc repro) o deja el CSV de respaldo en la raíz.\"\n",
    "    )\n",
    "\n",
    "# Normaliza tipos\n",
    "dataset_modified = dataset_modified.convert_dtypes()\n",
    "print(\"dtypes (primeras 8):\")\n",
    "print(dataset_modified.dtypes.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1760207922871,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "E6RjBG6G5o7M"
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1760207923660,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "khfKVJ9VTzby"
   },
   "outputs": [],
   "source": [
    "dataset_modified=pd.read_csv('df_final_validated.csv',low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1760207924576,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "rsXvmMOCcfLB"
   },
   "outputs": [],
   "source": [
    "dataset_modified=dataset_modified.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1f4H94m63gju9BJG2C60lnUhhjUlnNpUw"
    },
    "executionInfo": {
     "elapsed": 41292,
     "status": "ok",
     "timestamp": 1760207965870,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "K-SmlEx_Uzgg",
    "outputId": "1fb6ad9c-bc88-4591-c0f4-993337a49c2c"
   },
   "outputs": [],
   "source": [
    "dataset_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1760207966247,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "zIoj6-ip3DSu",
    "outputId": "4b1a613c-7456-455c-d68a-e2eb81faf20a"
   },
   "outputs": [],
   "source": [
    "print(dataset_modified.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SkkdviwWkU5"
   },
   "source": [
    "## Step 1 EDA - Clean Dataframe and describe columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2CnL9WSMwtK"
   },
   "source": [
    "###Classes and functions to clean columns and insert into pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966250,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "0Fq2rKqMMwVZ"
   },
   "outputs": [],
   "source": [
    "class CleanNumericColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    1. Lower-cases + trims selected columns\n",
    "    2. Casts to numeric (non-parsable values → NaN)\n",
    "    3. Imputes NaN with the training-set median\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        \"\"\"\n",
    "        columns : list of column names to clean; if None, all columns\n",
    "        \"\"\"\n",
    "        self.columns = columns              # hyper-parameter (used by __init__)\n",
    "\n",
    "    # ----------- Fit -----------\n",
    "    def fit(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        cols = self.columns or X_.columns   # default: every column\n",
    "\n",
    "        self.medians_ = {}                  # learned parameter(s) end with \"_\"\n",
    "        for c in cols:\n",
    "            col_clean = (\n",
    "                X_[c].astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.strip()\n",
    "                    .pipe(pd.to_numeric, errors='coerce')\n",
    "            )\n",
    "            self.medians_[c] = col_clean.median()\n",
    "        self.cols_ = cols                   # save for use in transform\n",
    "        return self                         # always return self\n",
    "\n",
    "    # ----------- Transform -----------\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols_:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.strip()\n",
    "                    .pipe(pd.to_numeric, errors='coerce')\n",
    "                    .fillna(self.medians_[c])\n",
    "            )\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.cols_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966252,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "rW6tpsXp8knv"
   },
   "outputs": [],
   "source": [
    "class CleanBooleanColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    1. Lower-cases + trims selected columns\n",
    "    2. Casts to numeric; NaN if coercion fails\n",
    "    3. Imputes NaN with the mode (most frequent) value from the *training* data\n",
    "    4. Converts to strict 0/1 flag based on equality with 1\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns          # list of columns (or None = all)\n",
    "\n",
    "    # ---------------- fit ----------------\n",
    "    def fit(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        cols = self.columns or X_.columns\n",
    "        self.modes_ = {}\n",
    "\n",
    "        for c in cols:\n",
    "            col_clean = (\n",
    "                X_[c].astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.strip()\n",
    "                    .pipe(pd.to_numeric, errors='coerce')\n",
    "            )\n",
    "            # .mode() returns Series; take the first element\n",
    "            self.modes_[c] = col_clean.mode(dropna=True)[0]\n",
    "\n",
    "        self.cols_ = cols\n",
    "        return self\n",
    "\n",
    "    # ------------- transform -------------\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols_:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.strip()\n",
    "                    .pipe(pd.to_numeric, errors='coerce')\n",
    "                    .fillna(self.modes_[c])\n",
    "                    .isin([1])          # True if value == 1\n",
    "                    .astype(int)        # → 0/1 integer\n",
    "            )\n",
    "        return X\n",
    "\n",
    "    # (Optional) expose feature names so ColumnTransformer → OneHotEncoder pipelines work\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.cols_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966254,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "RnZCLamwHHMv"
   },
   "outputs": [],
   "source": [
    "def _clean_string_columns(X, columns):\n",
    "    \"\"\"\n",
    "    • Cast to string\n",
    "    • Lower-case + strip\n",
    "    • Keep value only if it starts with 'http', else set to <NA>\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas DataFrame\n",
    "    columns : list[str] – columns to clean (must exist in X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : pandas DataFrame (copy of X with cleaned columns)\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    for c in columns:\n",
    "        X[c] = (\n",
    "            X[c].astype(str)\n",
    "                 .str.lower()\n",
    "                 .str.strip()\n",
    "                 .where(lambda s: s.str.startswith('http'), pd.NA)\n",
    "        )\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966256,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "l3VK6m1U9UcA"
   },
   "outputs": [],
   "source": [
    "class CleanStringColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless – nothing to learn\n",
    "        self.cols_ = self.columns or X.columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return _clean_string_columns(X, self.cols_)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.cols_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760207966257,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "Yzuq9a7HCvk6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _drop_rows_where_url_is_nan(X):\n",
    "    \"\"\"Return a copy of X with rows removed if url is missing (<NA>).\"\"\"\n",
    "    return X.loc[X['url'].notna()].reset_index(drop=True)\n",
    "\n",
    "drop_bad_url = FunctionTransformer(\n",
    "    _drop_rows_where_url_is_nan,\n",
    "    feature_names_out='one-to-one'   # keeps column names unchanged\n",
    ")\n",
    "\n",
    "def _drop_duplicate_url(X):\n",
    "    return X.drop_duplicates(subset='url', keep='first').reset_index(drop=True)\n",
    "\n",
    "drop_dup_url = FunctionTransformer(_drop_duplicate_url,\n",
    "                                   feature_names_out='one-to-one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966259,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "1X7IZdbZEdDw"
   },
   "outputs": [],
   "source": [
    "def delete_outliers(\n",
    "        df,\n",
    "        k=1.5,          # IQR multiplier\n",
    "        max_cols=1,     # row dropped if > max_cols columns flag it\n",
    "        return_counts=False\n",
    "    ):\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    col_counts = {}\n",
    "\n",
    "    mask_df = pd.DataFrame(index=df.index, columns=num_cols, dtype=bool)\n",
    "\n",
    "    for col in num_cols:\n",
    "        q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = q1 - k*iqr, q3 + k*iqr\n",
    "        col_mask = (df[col] < lower) | (df[col] > upper)\n",
    "\n",
    "        mask_df[col] = col_mask\n",
    "        col_counts[col] = int(col_mask.sum())\n",
    "\n",
    "    row_counts = mask_df.sum(axis=1)\n",
    "    row_mask   = row_counts > max_cols\n",
    "\n",
    "    cleaned_df = df.loc[~row_mask].reset_index(drop=True)\n",
    "\n",
    "    if return_counts:\n",
    "        return cleaned_df, pd.Series(col_counts).sort_values(ascending=False)\n",
    "    return cleaned_df\n",
    "\n",
    "def _drop_outliers(X):\n",
    "    # delete_outliers returns only the cleaned df when return_counts=False\n",
    "    return delete_outliers(X, k=1.5, max_cols=10, return_counts=False)\n",
    "\n",
    "drop_outliers = FunctionTransformer(_drop_outliers,\n",
    "                                    feature_names_out='one-to-one')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966260,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "Bra6NiPJGQZN"
   },
   "outputs": [],
   "source": [
    "def clip_numeric_ranges(X):\n",
    "    X = X.copy()\n",
    "    for c in columns_0_to_1:\n",
    "        if c in X.columns:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce').clip(0, 1)\n",
    "    for c in columns_neg1_to_1:\n",
    "        if c in X.columns:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce').clip(-1, 1)\n",
    "    for c in columns_neg1_to_0:\n",
    "        if c in X.columns:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce').clip(-1, 0)\n",
    "    return X\n",
    "\n",
    "clip_ranges = FunctionTransformer(clip_numeric_ranges,\n",
    "                                  feature_names_out='one-to-one')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU_92y1eWdMF"
   },
   "source": [
    "### Define column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966261,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "MQDDDcsa3jSW"
   },
   "outputs": [],
   "source": [
    "string_columns=['url']\n",
    "bool_columns=['data_channel_is_lifestyle', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech', 'data_channel_is_world', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday','is_weekend']\n",
    "num_columns=['LDA_00', 'LDA_01', 'LDA_02', 'LDA_03','LDA_04', 'abs_title_sentiment_polarity', 'abs_title_subjectivity', 'average_token_length', 'avg_negative_polarity', 'avg_positive_polarity', 'global_rate_negative_words', 'global_rate_positive_words', 'global_sentiment_polarity', 'global_subjectivity', 'kw_avg_avg', 'kw_avg_max', 'kw_avg_min', 'kw_max_avg', 'kw_max_max', 'kw_max_min', 'kw_min_avg', 'kw_min_max', 'kw_min_min', 'max_negative_polarity', 'max_positive_polarity', 'min_negative_polarity', 'min_positive_polarity', 'mixed_type_col', 'n_non_stop_unique_tokens', 'n_non_stop_words', 'n_tokens_content', 'n_tokens_title', 'n_unique_tokens', 'num_hrefs', 'num_imgs', 'num_keywords', 'num_self_hrefs', 'num_videos', 'rate_negative_words', 'rate_positive_words', 'timedelta', 'title_sentiment_polarity', 'title_subjectivity','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1760207966273,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "qxU7nZ9jHYvp",
    "outputId": "6d7a8ccc-e0d1-485a-fce1-28d620fe0850"
   },
   "outputs": [],
   "source": [
    "len(string_columns),len(bool_columns),len(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2ri0tWXHRM-"
   },
   "source": [
    "### Classify numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966275,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "mvLr7dzCHXYD"
   },
   "outputs": [],
   "source": [
    "# Clip values to match original dataset range\n",
    "columns_0_to_1 = [\"n_unique_tokens\",\"n_non_stop_words\",\"n_non_stop_unique_tokens\",\n",
    "           \"LDA_00\",\"LDA_01\",\"LDA_02\",\"LDA_03\",\"LDA_04\",\"global_rate_positive_words\",\n",
    "           \"global_subjectivity\",\"global_rate_negative_words\",\n",
    "           \"rate_positive_words\",\"rate_negative_words\",\"avg_positive_polarity\",\"min_positive_polarity\",\"max_positive_polarity\"\n",
    "           \"title_subjectivity\",\"abs_title_subjectivity\",\"abs_title_sentiment_polarity\"]\n",
    "\n",
    "columns_neg1_to_1 = [\"global_sentiment_polarity\",\"title_sentiment_polarity\"]\n",
    "\n",
    "columns_neg1_to_0 = [\"max_negative_polarity\", \"avg_negative_polarity\",\"min_negative_polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760207966279,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "cSNOU9Z455tC",
    "outputId": "5d479b4d-3313-4246-d58b-442d047ff407"
   },
   "outputs": [],
   "source": [
    "len(columns_0_to_1),len(columns_neg1_to_1),len(columns_neg1_to_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kW_COUp-enA"
   },
   "source": [
    "### Preprocess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760207966280,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "gme08Ek79t58"
   },
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num' , CleanNumericColumns(num_columns) ,  num_columns),\n",
    "        ('bool', CleanBooleanColumns(bool_columns),  bool_columns),\n",
    "        ('str' , CleanStringColumns(string_columns), string_columns),\n",
    "    ],\n",
    "    remainder='drop',                # keep only the columns above\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')     # ← keep pandas DataFrame & names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760207966281,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "2QtMyqO3J5T-"
   },
   "outputs": [],
   "source": [
    "cleaning_pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    " #   ('drop_bad_url', drop_bad_url),\n",
    " #   ('drop_dup_url',  drop_dup_url),\n",
    " #   ('drop_outliers',  drop_outliers),\n",
    " #   ('clip_ranges',    clip_ranges)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760207966282,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "cg0jxtyc-AK7"
   },
   "outputs": [],
   "source": [
    "# Fit *once* on your full DataFrame (no y needed)\n",
    "cleaned_df = cleaning_pipe.fit_transform(dataset_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1760207966285,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "InYKUv4c_jwp",
    "outputId": "eba1fb2c-7c15-4e32-ae8e-a0434c4bb405"
   },
   "outputs": [],
   "source": [
    "print(\"Original shape :\", dataset_modified.shape)\n",
    "print(\"Cleaned shape  :\", cleaned_df.shape)\n",
    "print(\"Any NA in url? :\", cleaned_df['url'].isna().any())\n",
    "print(\"Duplicate urls :\", cleaned_df['url'].duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX_aK6r8CLgi"
   },
   "source": [
    "### Describe the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760207966288,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "Y_YbQD6iDr-H",
    "outputId": "a5b7836e-8e71-4f63-c593-f1be33281d75"
   },
   "outputs": [],
   "source": [
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1760207966312,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "3B6JNznWCLJ0",
    "outputId": "c2d2e694-8736-40de-d977-7bbd09958430"
   },
   "outputs": [],
   "source": [
    "cleaned_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSQ_xBnnBaRy"
   },
   "source": [
    "## Step 2 EDA - graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InQEdN2eoR9A"
   },
   "source": [
    "### Function to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760207966314,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "vJIBRzDcn91e"
   },
   "outputs": [],
   "source": [
    "def graph_features(df,num_columns,bool_columns):\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  # 1.  Decide how many plots we need\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  n_plots = len(num_columns) * 2 + len(bool_columns)   # 2 plots per numeric feature\n",
    "\n",
    "  # choose grid size automatically (≤4 columns usually looks good)\n",
    "  n_cols  = 4\n",
    "  n_rows  = math.ceil(n_plots / n_cols)\n",
    "\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  # 2.  Create the figure canvas\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                          figsize=(n_cols * 4, n_rows * 3),\n",
    "                          constrained_layout=True)      # auto-spacing\n",
    "  axes = axes.ravel()        # 1-D iterator over all axes\n",
    "\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  # 3.  Draw the plots\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  idx = 0\n",
    "  BINS=60\n",
    "  # Numeric: histogram + boxplot\n",
    "  for col in num_columns:\n",
    "      # Histogram (+ optional KDE line)\n",
    "      sns.histplot(df[col],\n",
    "                  bins=BINS,\n",
    "                  ax=axes[idx],\n",
    "                  kde=True, color='steelblue')\n",
    "      axes[idx].set_title(f'{col}\\nHistogram', fontsize=9)\n",
    "      idx += 1\n",
    "\n",
    "      # Boxplot (vertical wastes less horizontal space)\n",
    "      sns.boxplot(y=df[col],\n",
    "                  ax=axes[idx],\n",
    "                  color='salmon')\n",
    "      axes[idx].set_title(f'{col}\\nBoxplot', fontsize=9)\n",
    "      idx += 1\n",
    "\n",
    "  # Boolean / nominal: countplot\n",
    "  for col in bool_columns:\n",
    "      sns.countplot(x=df[col],\n",
    "                    ax=axes[idx],\n",
    "                    palette='pastel')\n",
    "      axes[idx].set_title(f'{col}\\nCount', fontsize=9)\n",
    "      idx += 1\n",
    "\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  # 4.  Remove any unused axes to keep the grid tidy\n",
    "  # ───────────────────────────────────────────────────────────\n",
    "  for j in range(idx, len(axes)):\n",
    "      fig.delaxes(axes[j])\n",
    "\n",
    "  # Global style tweaks\n",
    "  sns.despine(fig=fig)           # remove top/right spines\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32460,
     "status": "ok",
     "timestamp": 1760207998775,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "V5i1swpED144",
    "outputId": "06a5f1bf-b668-4baf-b6ba-58a42e1d3e8e"
   },
   "outputs": [],
   "source": [
    "graph_features(df=cleaned_df,num_columns=num_columns,bool_columns=bool_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJF0m4s4CAt2"
   },
   "source": [
    "## ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6PT5xOA911X"
   },
   "source": [
    "### Split dataframe for Train, Validation and Test and drop columns that are redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRCn8NwjmyVJ"
   },
   "source": [
    "### Agregar analisis de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1760212779639,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "P-bX8QUFm4jz"
   },
   "outputs": [],
   "source": [
    "corr_matrix = cleaned_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "executionInfo": {
     "elapsed": 5639,
     "status": "ok",
     "timestamp": 1760212785283,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "eoxGp2MFm4Z4",
    "outputId": "12a2ebd0-0a32-4eed-b062-786912f86497"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h9cHPw0SMUG"
   },
   "source": [
    "##### The following columns where removed from the X\n",
    "\n",
    "\n",
    "\n",
    "1.   average_token_length since it is an average correlated to n_tokens_content\n",
    "2.   kw_avg_min since it is an average correlated to kw_min_min and kw_max_min\n",
    "3.   kw_avg_max since it is an average correlated to kw_max_min and kw_max_max\n",
    "4.   self_reference_min_shares since it is normally data obtained after models have been deployed\n",
    "5.   self_reference_max_shares since it is normally data obtained after models have been deployed\n",
    "6.   self_reference_avg_sharess since it is normally data obtained after models have been deployed\n",
    "7.   is_weekend since we have columns for saturday and sunday\n",
    "8.   weekday_is_sunday since we can determine by knowing if the other days did not apply\n",
    "9.  avg_positive_polarity since it is an abg correlated to min_positive_polarity and max_positive_polarity\n",
    "10.  avg_negative_polarity since it is an abg correlated to min_negative_polarity and max_negative_polarity\n",
    "11. url since it is a string column that can be used as the index\n",
    "12. shares since that is our output\n",
    "13. kw_avg_avg since it is correlated to kw_max_avg and kw_min_avg\n",
    "14. timedelta since it is a not predictive column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760208472065,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "1Rr0k0auB9pq"
   },
   "outputs": [],
   "source": [
    "#Dataframe for X\n",
    "index = dataset_modified[\"url\"]\n",
    "y = cleaned_df[\"shares\"]\n",
    "X=cleaned_df.drop(columns={'timedelta','average_token_length','kw_avg_min','kw_avg_max','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','is_weekend','weekday_is_sunday','avg_positive_polarity','avg_negative_polarity','url','shares','kw_avg_avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports mínimos para el split y métricas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# (opcional) por si el kernel se reinició\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1760208473356,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "hrBZcDlj9w-W",
    "outputId": "cffbc8b6-ad99-4153-ca66-e123ef36ee23"
   },
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=None\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_valtest, y_valtest,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=None\n",
    ")\n",
    "\n",
    "print('Original dataframe',dataset_modified.shape)\n",
    "print('Cleaned dataframe',cleaned_df.shape)\n",
    "print('X_train', X_train.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WZkVXBvbLYh"
   },
   "source": [
    "### Pipeline to improve features distributions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports mínimos para los pipelines ===\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760208616100,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "eU6jg6JHmE6O",
    "outputId": "9fbe16d5-bce3-4c29-bef9-322388fb63f5"
   },
   "outputs": [],
   "source": [
    "#Se elimino shares de num_cols\n",
    "\n",
    "string_columns=['url']\n",
    "bool_columns=['data_channel_is_lifestyle', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech', 'data_channel_is_world', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday']\n",
    "num_columns=['LDA_00', 'LDA_01', 'LDA_02', 'LDA_03','LDA_04', 'abs_title_sentiment_polarity', 'abs_title_subjectivity', 'global_rate_negative_words', 'global_rate_positive_words', 'global_sentiment_polarity', 'global_subjectivity', 'kw_max_avg', 'kw_max_max', 'kw_max_min', 'kw_min_avg', 'kw_min_max', 'kw_min_min', 'max_negative_polarity', 'max_positive_polarity', 'min_negative_polarity', 'min_positive_polarity', 'mixed_type_col', 'n_non_stop_unique_tokens', 'n_non_stop_words', 'n_tokens_content', 'n_tokens_title', 'n_unique_tokens', 'num_hrefs', 'num_imgs', 'num_keywords', 'num_self_hrefs', 'num_videos', 'rate_negative_words', 'rate_positive_words', 'title_sentiment_polarity', 'title_subjectivity']\n",
    "print(+len(num_columns)+len(bool_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760208667943,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "_buXz5wGk5Va"
   },
   "outputs": [],
   "source": [
    "# Variables numéricas:\n",
    "numeric_pipe = Pipeline(steps=[('impute_median',SimpleImputer(strategy='median')),('yeo-johnson_transformer',PowerTransformer(method='yeo-johnson',standardize=False)),('standard_scaler',StandardScaler())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1760208684211,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "BKbKCswWk66J"
   },
   "outputs": [],
   "source": [
    "# Variables categóricas binaries:\n",
    "bool_pipe = Pipeline(steps=[('impute_mode',SimpleImputer(strategy='most_frequent'))])\n",
    "bool_pipe2 = Pipeline(steps=[('impute_mode',SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2503,
     "status": "ok",
     "timestamp": 1760208706161,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "NHgomWDUksK7",
    "outputId": "0ce6acbd-e724-448f-9d13-80e8bf276abf"
   },
   "outputs": [],
   "source": [
    "# Conjuntas las transformaciones de todo tipo de variable y\n",
    "# deja sin procesar aquellas que hayas decidido no transformar:\n",
    "\n",
    "columnasTransformer = ColumnTransformer(transformers=[('num_pipe',numeric_pipe,num_columns),('bin_pipe',bool_pipe,bool_columns),],remainder='passthrough')\n",
    "\n",
    "columnasTransformer2 = ColumnTransformer(transformers=[('num_pipe',numeric_pipe,num_columns),('bin_pipe',bool_pipe2,bool_columns),],remainder='passthrough',verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "Xtmp = X_train.copy()\n",
    "tmp = columnasTransformer.fit_transform(Xtmp)\n",
    "tmp2=columnasTransformer2.fit_transform(Xtmp)\n",
    "print(\"Dimensión de los datos de entrada:\")\n",
    "print(\"antes de aplicar las transformaciones:\", Xtmp.shape)\n",
    "print(\"después de aplicar las transformaciones:\", tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMSit-MAdRdj"
   },
   "source": [
    "### Histogram after pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1760209008100,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "gP8rT6otiAo6",
    "outputId": "4c7d1c9f-ab01-4300-a32a-b79676773368"
   },
   "outputs": [],
   "source": [
    "tmp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26289,
     "status": "ok",
     "timestamp": 1760209039101,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "jfMcfgE-dUuE",
    "outputId": "7aef8ac5-6abc-44c4-f73e-33bb6f1b20ed"
   },
   "outputs": [],
   "source": [
    "graph_features(df=tmp2,num_columns=num_columns,bool_columns=bool_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3soN5g1qRtL"
   },
   "source": [
    "### Merge X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1525,
     "status": "ok",
     "timestamp": 1760209236588,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "2Myi0bE9qVaD",
    "outputId": "6f17d86e-7d57-43e9-fc6a-0c40c9d5fc59"
   },
   "outputs": [],
   "source": [
    "# Como se va a utilizar Validación-Cruzada, concatena los conjuntos de entrenamiento\n",
    "# y prueba en uno nuevo conjunto aumentado que llamaremos trainval:\n",
    "\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "\n",
    "Xtraintest = pd.concat([X_train,X_test])\n",
    "ytraintest = pd.concat([y_train,y_test])\n",
    "\n",
    "\n",
    "# *********** Aquí termina la sección de agregar código *************\n",
    "\n",
    "\n",
    "# Veamos cuántas variables nuevas se introducen con las transformaciones One-Hot-Encoding:\n",
    "Xtmp = Xtraintest.copy()\n",
    "tmp = columnasTransformer.fit_transform(Xtmp)\n",
    "print(\"Dimensión de las variables de entrada ANTES de las transformaciones:\", Xtmp.shape)\n",
    "print(\"Dimensión de las variables de entrada DESPUÉS de las transformaciones:\", tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNBx1LNNbUdx"
   },
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1760209245483,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "Tg332em7t9Du"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "\n",
    "# Helper: RMSE scorer (scikit-learn does not provide it directly)\n",
    "rmse_scorer = make_scorer(\n",
    "    mean_squared_error,\n",
    "    greater_is_better=False,   # tell sklearn that “bigger is worse”\n",
    "    squared=False              # √MSE  instead of MSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760209247044,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "OuU7zEscrI9l"
   },
   "outputs": [],
   "source": [
    "def mi_fun_nosampling(modelo, nombre, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate a *regression* model (wrapped in a Pipeline with the global\n",
    "    columnasTransformer) using repeated k-fold CV and several regression\n",
    "    metrics, then print the aggregated results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    modelo : estimator\n",
    "        Any scikit-learn compatible regressor (e.g., RandomForestRegressor).\n",
    "    nombre : str\n",
    "        A tag that appears in the printed summary.\n",
    "    X : pd.DataFrame or np.ndarray\n",
    "        Features.\n",
    "    y : array-like\n",
    "        Target vector.\n",
    "    \"\"\"\n",
    "\n",
    "    print('No sampling method used with column transformation, results:')\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('ct', columnasTransformer),\n",
    "        ('model', modelo)\n",
    "    ])\n",
    "\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=5)\n",
    "\n",
    "    # Metrics to compute\n",
    "    mis_metricas = {\n",
    "        'rmse' : rmse_scorer,                        # root-mean-squared error\n",
    "        'mae'  : 'neg_mean_absolute_error',          # will be negated back\n",
    "        'mape' : 'neg_mean_absolute_percentage_error',\n",
    "        'r2'   : 'r2'\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        X, np.ravel(y),\n",
    "        scoring=mis_metricas,\n",
    "        cv=cv,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Pretty printing\n",
    "    print(f'>> {nombre}')\n",
    "    for metric_name in mis_metricas.keys():\n",
    "        values = scores[f'test_{metric_name}']\n",
    "        # flip the sign for “neg_...” scorers so that smaller is worse\n",
    "        if metric_name in ['mae', 'mape', 'rmse']:\n",
    "            values = -values\n",
    "        mean_val = np.nanmean(values)\n",
    "        std_val  = np.nanstd(values)\n",
    "        print(f'\\t{metric_name:5s}: {mean_val:.4f} ({std_val:.3f})')\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760209250058,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 360
    },
    "id": "yTQ3s74srJ6k"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "def mi_fun_grid(modelo, nombre, X, y, dicc_grid=None):\n",
    "    \"\"\"\n",
    "    Grid-search helper for REGRESSION models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    modelo : estimator\n",
    "        Any scikit-learn compatible regressor (e.g., XGBRegressor()).\n",
    "    nombre : str\n",
    "        Name that appears in the printed summary.\n",
    "    X : pd.DataFrame or np.ndarray\n",
    "        Feature matrix.\n",
    "    y : array-like\n",
    "        Target vector.\n",
    "    dicc_grid : dict or list of dicts\n",
    "        Hyper-parameter grid to explore (as in GridSearchCV).\n",
    "    \"\"\"\n",
    "    print('Find best parameters while using column transformation')\n",
    "\n",
    "    # 1. Pipeline ----------------------------------------------------\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('ct', columnasTransformer),  # assumes you defined this globally\n",
    "        ('model', modelo)\n",
    "    ])\n",
    "\n",
    "    # 2. Scoring dictionary -----------------------------------------\n",
    "    mis_metricas = {\n",
    "        'rmse':  'neg_root_mean_squared_error',      # lower is better\n",
    "        'mae':   'neg_mean_absolute_error',\n",
    "        'mape':  'neg_mean_absolute_percentage_error',\n",
    "        'r2':    'r2'\n",
    "    }\n",
    "\n",
    "    # 3. CV strategy -------------------------------------------------\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "    # 4. Grid search -------------------------------------------------\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=dicc_grid,\n",
    "        cv=cv,\n",
    "        scoring=mis_metricas,\n",
    "        refit='rmse',           # the model returned by .best_estimator_ minimises RMSE\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 5. Fit ---------------------------------------------------------\n",
    "    grid_result = grid.fit(X, np.ravel(y))\n",
    "\n",
    "    # 6. Report ------------------------------------------------------\n",
    "    best_rmse = -grid_result.best_score_   # flip sign back to positive RMSE\n",
    "    print(f'>> {nombre}')\n",
    "    print(f'Mejor RMSE (CV): {best_rmse:.4f} usando {grid_result.best_params_}')\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "    # Optional: display the mean CV value for every metric\n",
    "    for m in mis_metricas:\n",
    "        vals = grid_result.cv_results_[f'mean_test_{m}']\n",
    "        stds = grid_result.cv_results_[f'std_test_{m}']\n",
    "        # flip sign for neg_ scorers\n",
    "        if m in ['rmse', 'mae', 'mape']:\n",
    "            vals = -vals\n",
    "        print(f'{m:5s}: {vals.min():.4f} – {vals.max():.4f}  (std avg {stds.mean():.3f})')\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    return grid_result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FjlHwBsz6MZ"
   },
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYUlhxtRqjpz"
   },
   "source": [
    "### Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Celda A: helpers =====\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# OJO: esta función debe existir UNA sola vez en todo el notebook\n",
    "def mi_fun_grid(modelo, nombre, X, y, dicc_grid=None):\n",
    "    \"\"\"\n",
    "    Grid-search helper para MODELOS DE REGRESIÓN.\n",
    "    Devuelve el objeto GridSearchCV ya entrenado (con .best_estimator_ y .best_score_).\n",
    "    Requiere que 'columnasTransformer' exista en el notebook.\n",
    "    \"\"\"\n",
    "    print('Find best parameters while using column transformation')\n",
    "\n",
    "    # pipeline: usa tu columnasTransformer global\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('ct', columnasTransformer),\n",
    "        ('model', modelo)\n",
    "    ])\n",
    "\n",
    "    # métricas\n",
    "    mis_metricas = {\n",
    "        'rmse':  'neg_root_mean_squared_error',\n",
    "        'mae':   'neg_mean_absolute_error',\n",
    "        'mape':  'neg_mean_absolute_percentage_error',\n",
    "        'r2':    'r2'\n",
    "    }\n",
    "\n",
    "    # validación cruzada\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "    # grid search\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=dicc_grid,\n",
    "        cv=cv,\n",
    "        scoring=mis_metricas,\n",
    "        refit='rmse',     # el mejor minimiza RMSE\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # entrenar\n",
    "    grid_result = grid.fit(X, np.ravel(y))\n",
    "\n",
    "    # reporte\n",
    "    best_rmse = -grid_result.best_score_\n",
    "    print(f'>> {nombre}')\n",
    "    print(f'Mejor RMSE (CV): {best_rmse:.4f} usando {grid_result.best_params_}')\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    for m in mis_metricas:\n",
    "        vals = grid_result.cv_results_[f'mean_test_{m}']\n",
    "        stds = grid_result.cv_results_[f'std_test_{m}']\n",
    "        if m in ['rmse', 'mae', 'mape']:\n",
    "            vals = -vals\n",
    "        print(f'{m:5s}: {vals.min():.4f} – {vals.max():.4f}  (std avg {stds.mean():.3f})')\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "    return grid_result  # <--- IMPORTANTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Celda B: entrenamiento LR + KNN =====\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Sanidad: verifica que tenemos datos\n",
    "print(\"Shapes:\",\n",
    "      \"Xtraintest\", Xtraintest.shape,\n",
    "      \"| ytraintest\", ytraintest.shape,\n",
    "      \"| X_val\", X_val.shape,\n",
    "      \"| y_val\", y_val.shape)\n",
    "\n",
    "# --- Regresión Lineal ---\n",
    "nombre_lr = 'Linear_Regression'\n",
    "modelo_lr = LinearRegression()\n",
    "grid_lr = {\n",
    "    'model__fit_intercept': [True, False],\n",
    "    'model__copy_X': [True, False],\n",
    "    'model__positive': [False, True],\n",
    "}\n",
    "gs_lr = mi_fun_grid(modelo_lr, nombre_lr, Xtraintest, ytraintest, dicc_grid=grid_lr)\n",
    "best_lr = gs_lr.best_estimator_\n",
    "best_lr_rmse = -gs_lr.best_score_\n",
    "\n",
    "# --- KNN Regressor ---\n",
    "nombre_knn = 'K_neighbors_nearest'\n",
    "modelo_knn = KNeighborsRegressor()\n",
    "grid_knn = {\n",
    "    'model__n_neighbors': [5, 11, 15, 21],\n",
    "    'model__weights': ['uniform'],\n",
    "    'model__algorithm': ['auto'],\n",
    "    'model__p': [1, 2],\n",
    "}\n",
    "gs_knn = mi_fun_grid(modelo_knn, nombre_knn, Xtraintest, ytraintest, dicc_grid=grid_knn)\n",
    "best_knn = gs_knn.best_estimator_\n",
    "best_knn_rmse = -gs_knn.best_score_\n",
    "\n",
    "print(\"\\nListo ✅  best_lr y best_knn definidos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Celda C: artefactos DVC =====\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "import json, pandas as pd, numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# carpetas de salida\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"reports/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Guardar modelos entrenados\n",
    "dump(best_lr,  \"models/Linear_Regression.joblib\")\n",
    "dump(best_knn, \"models/KNN.joblib\")\n",
    "\n",
    "# 2) Métricas en VALIDACIÓN\n",
    "def _metricas(nombre, y_true, y_pred):\n",
    "    rmse_val = float(np.sqrt(mean_squared_error(y_true, y_pred)))  # SIN squared=False\n",
    "    mae_val  = float(mean_absolute_error(y_true, y_pred))\n",
    "    r2_val   = float(r2_score(y_true, y_pred))\n",
    "    return {\"model\": nombre, \"rmse_val\": rmse_val, \"mae_val\": mae_val, \"r2_val\": r2_val}\n",
    "\n",
    "artefactos = []\n",
    "artefactos.append(_metricas(\"Linear_Regression\", y_val, best_lr.predict(X_val)))\n",
    "artefactos.append(_metricas(\"KNN\",               y_val, best_knn.predict(X_val)))\n",
    "\n",
    "# 3) CSV resumen\n",
    "pd.DataFrame(artefactos).to_csv(\"reports/models/cv_results_summary.csv\", index=False)\n",
    "\n",
    "# 4) JSON con mejor por RMSE\n",
    "best = min(artefactos, key=lambda d: d[\"rmse_val\"])\n",
    "with open(\"reports/models/metrics.json\", \"w\") as f:\n",
    "    json.dump({\"best_model\": best[\"model\"], \"rmse_val\": best[\"rmse_val\"]}, f, indent=2)\n",
    "\n",
    "print(\"✅ Artefactos guardados:\")\n",
    "print(\"- models/Linear_Regression.joblib\")\n",
    "print(\"- models/KNN.joblib\")\n",
    "print(\"- reports/models/cv_results_summary.csv\")\n",
    "print(\"- reports/models/metrics.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQX1LLzzMB8h"
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5861044,
     "status": "ok",
     "timestamp": 1760127112493,
     "user": {
      "displayName": "Felipe de Jesús Gutiérrez Dávila",
      "userId": "01500989835494077702"
     },
     "user_tz": 240
    },
    "id": "bkM1RIrqzdGf",
    "outputId": "a7de8ab1-c744-4229-8348-5db3359ddaed"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "#\"\"\"class sklearn.tree.DecisionTreeRegressor(*, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0, monotonic_cst=None)\"\"\"\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "#nombre = 'Decision_tree'\n",
    "#modelo = DecisionTreeRegressor()\n",
    "\n",
    "#Grid parameters\n",
    "#dicc_grid = {\n",
    "    #'model__criterion': ['squared_error', 'absolute_error'],  # loss function\n",
    "    #'model__splitter': ['best'],        # how to choose splits\n",
    "    #'model__max_depth': [None, 7, 20],  # tree depth limit\n",
    "    #'model__min_samples_split': [2, 7, 15],   # minimum samples to split an internal node\n",
    "    #'model__min_samples_leaf': [1, 2, 6, 10],  # minimum samples at a leaf node\n",
    "   # 'model__max_features': [None, 'sqrt'],# number of features to consider when looking for best split\n",
    "    #'model__max_leaf_nodes': [None, 10, 20, 50]  # maximum number of leaf nodes\n",
    "#}\n",
    "#Evaluate modelo WITHOUT over/sub sampling and WITH column transformer\n",
    "#mi_fun_grid(modelo,nombre, Xtraintest, ytraintest,dicc_grid=dicc_grid)\n",
    "#modelo = DecisionTreeRegressor(criterion='gini',max_depth=3,max_features=25,min_samples_split=3,random_state=1)\n",
    "\n",
    "\n",
    "#Evaluate modelo WITHOUT over/sub sampling\n",
    "#mi_fun_nosampling(modelo,nombre, Xtraintest, ytraintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU4cB3m3I9AN"
   },
   "source": [
    "Find best parameters while using column transformation\n",
    "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n",
    ">> Decision_tree\n",
    "Mejor RMSE (CV): 23400.2251 usando {'model__criterion': 'absolute_error', 'model__max_depth': 7, 'model__max_features': 'sqrt'}\n",
    "------------------------------------------------------------------------------------------\n",
    "rmse : 23400.2251 – 39427.2034  (std avg 5531.391)\n",
    "mae  : 3138.4086 – 6596.0320  (std avg 385.893)\n",
    "mape : 0.6508 – 3.4537  (std avg 0.298)\n",
    "r2   : -2.5399 – -0.0223  (std avg 0.896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2G0hboTd0Cmz"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jj0G5QRizgMR",
    "outputId": "f49d0e7d-ee89-443e-f0f6-2a8c2d30806a"
   },
   "outputs": [],
   "source": [
    "# Bosque Aleatorio-RandomForest-RF:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "#nombre = 'Random_forest'\n",
    "#modelo=RandomForestRegressor()\n",
    "\n",
    "#Grid parameters\n",
    "#dicc_grid = {\n",
    "    ##'model__criterion': ['squared_error', 'absolute_error'],\n",
    "    #'model__max_depth': [None, 15, 30],       # maximum depth of each tree\n",
    "    #'model__min_samples_split': [2, 5, 10],          # min samples to split an internal node\n",
    "    #'model__min_samples_leaf': [1, 2, 4],            # min samples at a leaf node\n",
    "    #'model__max_features': ['sqrt', None],   # number of features considered for split\n",
    "    #'model__bootstrap': [True, False],               # whether to use bootstrap samples\n",
    "    #'model__max_leaf_nodes': [None, 20, 50, 100]     # optional, controls model complexity\n",
    "#}\n",
    "##Evaluate modelo WITHOUT over/sub sampling and WITH column transformer\n",
    "#mi_fun_grid(modelo,nombre, Xtraintest, ytraintest,dicc_grid=dicc_grid)\n",
    "#modelo = RandomForestRegressor(criterion='entropy',max_depth=17,max_features=7,min_samples_split=11,n_estimators=31,random_state=1)\n",
    "\n",
    "\n",
    "#Evaluate modelo WITHOUT over/sub sampling\n",
    "#mi_fun_nosampling(modelo,nombre, Xtraintest, ytraintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHUKa6Oh0F4O"
   },
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jziVFdXbzjx1"
   },
   "outputs": [],
   "source": [
    "# XGBoosting:\n",
    "# https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "# https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "#nombre = 'Extreme_Gradient_Boost'\n",
    "#modelo=XGBRegressor()\n",
    "\n",
    "#Grid parameters\n",
    "#dicc_grid =  {\n",
    "    # Tree complexity\n",
    "    #'model__n_estimators': [50, 100, 5¿200],        # number of boosting rounds\n",
    "    #'model__max_depth': [3, 10, 20],             # tree depth\n",
    "    #'model__min_child_weight': [1, 3, 5],          # min sum of instance weight (controls overfitting)\n",
    "\n",
    "    # Learning dynamics\n",
    "    #'model__learning_rate': [0.01, 0.05, 0.1, 0.3], # shrinkage step\n",
    "    #'model__subsample': [0.6, 0.8, 1.0],            # row sampling\n",
    "    #'model__colsample_bytree': [0.6, 0.8, 1.0],     # feature sampling per tree\n",
    "\n",
    "    # Regularization\n",
    "    #'model__gamma': [0, 0.1, 0.3, 0.5],             # minimum loss reduction to make a split\n",
    "    #'model__reg_alpha': [0, 0.1, 0.5, 1.0],         # L1 regularization\n",
    "    #'model__reg_lambda': [0.5, 1.0, 2.0]            # L2 regularization\n",
    "#}\n",
    "#Evaluate modelo WITHOUT over/sub sampling and WITH column transformer,\n",
    "#mi_fun_grid(modelo,nombre, Xtraintest, ytraintest,dicc_grid=dicc_grid)\n",
    "#modelo=XGBRegressor(booster='gbtree',n_estimators=30,learning_rate=0.2,max_depth=3,max_depth=3,subsample=0.8,random_state=1)\n",
    "\n",
    "\n",
    "#Evaluate modelo WITHOUT over/sub sampling\n",
    "#mi_fun_nosampling(modelo,nombre, Xtraintest, ytraintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcub02PO0Inq"
   },
   "source": [
    "### Neuronal network MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrkIKrBX0RLi"
   },
   "source": [
    "### Support vector machine SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Up99RWgIzmeA",
    "outputId": "6891d0f6-db55-4240-a10a-fa076252722e"
   },
   "outputs": [],
   "source": [
    "# Red neuronal de Perceptrón Multicapa-MLP:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "#nombre = \"Red Neuronal Multicapa MLP\"\n",
    "#modelo = MLPRegressor()\n",
    "\n",
    "\n",
    "#Grid parameters\n",
    "#dicc_grid = {\n",
    "    # Network architecture\n",
    "    #'model__hidden_layer_sizes': [\n",
    "    #    (50,), (100,), (100, 50), (50, 50, 50)\n",
    "    #],  # number of layers and neurons per layer\n",
    "\n",
    "    # Activation and solver\n",
    "    #'model__activation': ['relu', 'tanh', 'logistic'],   # nonlinearities\n",
    "    #'model__solver': ['adam', 'lbfgs'],                  # optimizer\n",
    "\n",
    "    # Regularization and learning\n",
    "    #'model__alpha': [0.0001, 0.001, 0.01],              # L2 penalty\n",
    "    #'model__learning_rate': ['constant', 'adaptive'],    # learning rate schedule\n",
    "    #'model__learning_rate_init': [0.001, 0.01, 0.05],    # initial learning rate\n",
    "   # 'model__early_stopping': [True]                      # helps avoid overfitting\n",
    "#}\n",
    "#Evaluate modelo WITHOUT over/sub sampling and WITH column transformer\n",
    "#mi_fun_grid(modelo,nombre, Xtraintest, ytraintest,dicc_grid=dicc_grid)\n",
    "#modelo = MLPRegressor(hidden_layer_sizes=(75,),activation='tanh',solver='adam',learning_rate='constant',learning_rate_init=0.0001,max_iter=2000,random_state=1)\n",
    "\n",
    "# Selecciona el método de submuestreo o sobremuestreo, si lo deseas incluir.\n",
    "#metodo_uo = SMOTETomek(random_state=1)\n",
    "\n",
    "#Evaluate modelo WITHOUT over/sub sampling\n",
    "#mi_fun_nosampling(modelo,nombre, Xtraintest, ytraintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXWss2kizppo"
   },
   "outputs": [],
   "source": [
    "# Máquina de Vectores de Soporte-SVM:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "\n",
    "# ************* Inlcuye aquí tu código:**************************\n",
    "\n",
    "#nombre = 'Support Vector Machine SVM'\n",
    "#modelo = SVR()\n",
    "\n",
    "#Grid parameters\n",
    "#dicc_grid =  {\n",
    "    #'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    #'model__C': [0.1, 1, 10, 100],          # regularization parameter\n",
    "    #'model__epsilon': [0.01, 0.1, 0.2, 0.5],# insensitive loss margin\n",
    "    #'model__gamma': ['scale', 'auto'],      # kernel coefficient\n",
    "    #'model__degree': [2, 3, 4]              # only used for 'poly' kernel\n",
    "#}\n",
    "#Evaluate modelo WITHOUT over/sub sampling and WITH column transformer\n",
    "#mi_fun_grid(modelo,nombre, Xtraintest, ytraintest,dicc_grid=dicc_grid)\n",
    "#modelo = SVR(C=3.25,kernel='rbf',gamma='scale',random_state=1)\n",
    "\n",
    "\n",
    "#Evaluate modelo WITHOUT over/sub sampling\n",
    "#mi_fun_nosampling(modelo,nombre, Xtraintest, ytraintest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDtQ6rIjBlDK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
